{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Machine Unlearning Pipeline\n",
    "\n",
    "**Folder structure expected:**\n",
    "```\n",
    "pipeline/\n",
    "â”œâ”€â”€ data/          (dataset.py, manager.py)\n",
    "â”œâ”€â”€ evaluation/    (evaluator.py)\n",
    "â””â”€â”€ unlearning/    (config.py, unlearner.py, adapters/, losses/, utils/)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install timm peft datasets optuna -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model & Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"resnet50.a1h_in1k\"\n",
    "FORGET_CLASS = 9  # Ostrich\n",
    "\n",
    "base_model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=1000)\n",
    "base_model.eval()\n",
    "base_model.to(DEVICE)\n",
    "\n",
    "# Timm provides the exact resize/normalize config the model expects\n",
    "data_config = timm.data.resolve_model_data_config(base_model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "print(\"Model ready on\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data â€” load once, reuse across all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.data import ImageNetDataManager\n",
    "\n",
    "data_manager = ImageNetDataManager(\n",
    "    train_files=\"imagenet_shards/train/*.parquet\",\n",
    "    val_files=\"imagenet_shards/val/*.parquet\",\n",
    ")\n",
    "\n",
    "# This is now < 1 second â€” safe to call inside an Optuna trial\n",
    "val_loader, f_loader, r_loader = data_manager.get_loaders(\n",
    "    forget_class=FORGET_CLASS,\n",
    "    transforms=transforms,\n",
    "    batch_size=32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Base model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pipeline.evaluation import ImageNetEvaluator\n",
    "\n",
    "base_eval = ImageNetEvaluator(\n",
    "    base_model, val_loader, device=DEVICE, forget_class=FORGET_CLASS\n",
    ")\n",
    "base_eval.run()\n",
    "\n",
    "print(\"Base model metrics:\")\n",
    "print(json.dumps(base_eval.summary(), indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Single unlearning run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "for name, module in base_model.named_modules():\n",
    "    if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "        print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.unlearning import Unlearner, UnlearnerConfig\n",
    "\n",
    "resnet_target_modules = [\n",
    "    \"layer4.0.conv1\",\n",
    "    \"layer4.0.conv2\",\n",
    "    \"layer4.0.conv3\",\n",
    "    \"layer4.1.conv1\",\n",
    "    \"layer4.1.conv2\",\n",
    "    \"layer4.1.conv3\",\n",
    "    \"layer4.2.conv1\",\n",
    "    \"layer4.2.conv2\",\n",
    "    \"layer4.2.conv3\",\n",
    "    \"fc\",\n",
    "]\n",
    "\n",
    "resnet_config = UnlearnerConfig(\n",
    "    epochs=5,\n",
    "    lr=0.00019770545752611148,\n",
    "    rank=4,\n",
    "    alpha=54,\n",
    "    lambda_retain=3.6500479489591697,\n",
    "    device=DEVICE,\n",
    "    target_modules=resnet_target_modules,\n",
    ")\n",
    "\n",
    "mobilenet_target_modules = [\n",
    "    \"blocks.5.2.conv_pw\",\n",
    "    \"blocks.5.2.conv_pwl\",\n",
    "    \"blocks.6.0.conv_pw\",\n",
    "    \"blocks.6.0.conv_pwl\",\n",
    "    \"conv_head\",\n",
    "    \"classifier\",\n",
    "]\n",
    "\n",
    "mobilenet_config = UnlearnerConfig(\n",
    "    epochs=5,\n",
    "    lr=0.00010447586363322035,\n",
    "    rank=47,\n",
    "    alpha=39,\n",
    "    lambda_retain=0.9665918467988226,\n",
    "    device=DEVICE,\n",
    "    target_modules=mobilenet_target_modules,\n",
    ")\n",
    "\n",
    "vgg_target_modules = [\n",
    "    \"features.24\",\n",
    "    \"features.26\",\n",
    "    \"features.28\",\n",
    "    \"classifier.0\",\n",
    "    \"classifier.3\",\n",
    "    \"classifier.6\",\n",
    "]\n",
    "\n",
    "vgg_config = UnlearnerConfig(\n",
    "    epochs=5,\n",
    "    lr=0.0001028617924417038,\n",
    "    rank=8,\n",
    "    alpha=31,\n",
    "    lambda_retain=0.001,\n",
    "    device=DEVICE,\n",
    "    target_modules=vgg_target_modules,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearner = Unlearner(\n",
    "    model=base_model,  # Cloned internally â€” base_model is untouched\n",
    "    forget_loader=f_loader,\n",
    "    retain_loader=r_loader,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "trained_model = unlearner.train()\n",
    "trained_model.save_pretrained(\"./checkpoints/unlearned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Post-unlearning evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearned_eval = ImageNetEvaluator(\n",
    "    trained_model, val_loader, device=DEVICE, forget_class=FORGET_CLASS\n",
    ")\n",
    "unlearned_eval.run()\n",
    "\n",
    "print(\"Unlearned model metrics:\")\n",
    "print(json.dumps(unlearned_eval.summary(), indent=4))\n",
    "\n",
    "# Side-by-side delta\n",
    "base = base_eval.summary()\n",
    "after = unlearned_eval.summary()\n",
    "print(\"\\nDelta (unlearned âˆ’ base):\")\n",
    "print(json.dumps({k: round(after[k] - base[k], 6) for k in base}, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optuna hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import optuna\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Move base model to CPU so deep-copies inside trials don't compete for GPU RAM\n",
    "base_model.cpu()\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    target_modules = [\n",
    "        \"layer4.0.conv1\",\n",
    "        \"layer4.0.conv2\",\n",
    "        \"layer4.0.conv3\",\n",
    "        \"layer4.1.conv1\",\n",
    "        \"layer4.1.conv2\",\n",
    "        \"layer4.1.conv3\",\n",
    "        \"layer4.2.conv1\",\n",
    "        \"layer4.2.conv2\",\n",
    "        \"layer4.2.conv3\",\n",
    "        \"fc\",\n",
    "    ]\n",
    "\n",
    "    config = UnlearnerConfig(\n",
    "        lr=trial.suggest_float(\"lr\", 5e-5, 5e-4, log=True),\n",
    "        epochs=trial.suggest_int(\"epochs\", 3, 10),\n",
    "        rank=trial.suggest_int(\"rank\", 4, 64),\n",
    "        alpha=trial.suggest_int(\"alpha\", 4, 64),\n",
    "        lambda_retain=trial.suggest_float(\"lambda_retain\", 0.5, 5.0),\n",
    "        device=DEVICE,\n",
    "        target_modules=target_modules,\n",
    "    )\n",
    "\n",
    "    unlearner = Unlearner(\n",
    "        model=base_model,  # deepcopy happens inside Unlearner.__init__\n",
    "        forget_loader=f_loader,\n",
    "        retain_loader=r_loader,\n",
    "        config=config,\n",
    "    )\n",
    "    model = unlearner.train()\n",
    "\n",
    "    # Fast evaluation on a validation subset\n",
    "    fast_loader = DataLoader(\n",
    "        Subset(val_loader.dataset, list(range(2000))),\n",
    "        batch_size=64,\n",
    "        num_workers=2,\n",
    "    )\n",
    "    ev = ImageNetEvaluator(model, fast_loader, device=DEVICE, forget_class=FORGET_CLASS)\n",
    "    ev.run()\n",
    "    metrics = ev.retain_forget_accuracy()\n",
    "\n",
    "    del model, unlearner\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Minimise forget_acc, maximise retain_acc\n",
    "    return metrics[\"forget_acc\"], metrics[\"retain_acc\"]\n",
    "\n",
    "\n",
    "study = optuna.create_study(directions=[\"minimize\", \"maximize\"])\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(f\"Completed {len(study.trials)} trials.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Leaderboard â€” top trials that successfully unlearned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.trial import TrialState\n",
    "\n",
    "all_trials = [t for t in study.trials if t.state == TrialState.COMPLETE]\n",
    "\n",
    "# Only models that fully unlearned (forget acc < 0.5%)\n",
    "successful = [t for t in all_trials if t.values[0] < 0.005]\n",
    "\n",
    "# Rank by retain accuracy (highest first)\n",
    "top10 = sorted(successful, key=lambda t: t.values[1], reverse=True)[:10]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ðŸ† TOP 10 LEADERBOARD\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not top10:\n",
    "    print(\"âŒ No trials achieved < 0.5% forget accuracy.\")\n",
    "else:\n",
    "    for i, trial in enumerate(top10):\n",
    "        f_acc, r_acc = trial.values\n",
    "        print(f\"Rank #{i+1}\")\n",
    "        print(f\"  Forget Acc : {f_acc*100:.2f}%\")\n",
    "        print(f\"  Retain Acc : {r_acc*100:.2f}%\")\n",
    "        print(f\"  Params     : {trial.params}\")\n",
    "        print(\"-\" * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
